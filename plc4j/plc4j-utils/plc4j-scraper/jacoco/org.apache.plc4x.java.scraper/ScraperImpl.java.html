<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>ScraperImpl.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">PLC4J: Utils: Scraper</a> &gt; <a href="index.source.html" class="el_package">org.apache.plc4x.java.scraper</a> &gt; <span class="el_source">ScraperImpl.java</span></div><h1>ScraperImpl.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.plc4x.java.scraper;

import org.apache.commons.collections4.MultiValuedMap;
import org.apache.commons.collections4.multimap.ArrayListValuedHashMap;
import org.apache.commons.lang3.Validate;
import org.apache.commons.lang3.concurrent.BasicThreadFactory;
import org.apache.commons.lang3.tuple.Triple;
import org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;
import org.apache.commons.pool2.impl.GenericKeyedObjectPool;
import org.apache.commons.pool2.impl.GenericKeyedObjectPoolConfig;
import org.apache.plc4x.java.PlcDriverManager;
import org.apache.plc4x.java.api.PlcConnection;
import org.apache.plc4x.java.scraper.config.ScraperConfiguration;
import org.apache.plc4x.java.scraper.exception.ScraperException;
import org.apache.plc4x.java.scraper.util.PercentageAboveThreshold;
import org.apache.plc4x.java.utils.connectionpool.PooledPlcDriverManager;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.concurrent.*;

/**
 * Main class that orchestrates scraping.
 *
 * @deprecated Scraper is deprecated please use {@link org.apache.plc4x.java.scraper.triggeredscraper.TriggeredScraperImpl} instead all functions are supplied as well
 */
@Deprecated
public class ScraperImpl implements Scraper {

<span class="fc" id="L52">    private static final Logger LOGGER = LoggerFactory.getLogger(ScraperImpl.class);</span>

<span class="fc" id="L54">    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(10,</span>
        new BasicThreadFactory.Builder()
<span class="fc" id="L56">            .namingPattern(&quot;scheduler-thread-%d&quot;)</span>
<span class="fc" id="L57">            .daemon(false)</span>
<span class="fc" id="L58">            .build()</span>
    );
<span class="fc" id="L60">    private final ExecutorService handlerPool = Executors.newFixedThreadPool(4,</span>
        new BasicThreadFactory.Builder()
<span class="fc" id="L62">            .namingPattern(&quot;handler-thread-%d&quot;)</span>
<span class="fc" id="L63">            .daemon(true)</span>
<span class="fc" id="L64">            .build()</span>
    );

    private final ResultHandler resultHandler;

<span class="fc" id="L69">    private final MultiValuedMap&lt;ScrapeJob, ScraperTask&gt; tasks = new ArrayListValuedHashMap&lt;&gt;();</span>
<span class="fc" id="L70">    private final MultiValuedMap&lt;ScraperTask, ScheduledFuture&lt;?&gt;&gt; futures = new ArrayListValuedHashMap&lt;&gt;();</span>
    private final PlcDriverManager driverManager;
    private final List&lt;ScrapeJob&gt; jobs;

    /**
     * default constructor
     * @param resultHandler handler for acquired data
     * @param driverManager handler for Plc connection
     * @param jobs list of scrapings jobs to be executed
     */
<span class="fc" id="L80">    public ScraperImpl(ResultHandler resultHandler, PlcDriverManager driverManager, List&lt;ScrapeJob&gt; jobs) {</span>
<span class="fc" id="L81">        this.resultHandler = resultHandler;</span>
<span class="fc" id="L82">        Validate.notEmpty(jobs);</span>
<span class="fc" id="L83">        this.driverManager = driverManager;</span>
<span class="fc" id="L84">        this.jobs = jobs;</span>
<span class="fc" id="L85">    }</span>

    /**
     * Creates a Scraper instance from a configuration.
     * By default a {@link PooledPlcDriverManager} is used.
     * @param config Configuration to use.
     * @param resultHandler handler for acquired data
     */
    public ScraperImpl(ScraperConfiguration config, ResultHandler resultHandler) throws ScraperException {
<span class="nc" id="L94">        this(resultHandler, createPooledDriverManager(), config.getJobs());</span>
<span class="nc" id="L95">    }</span>

    /**
     * Min Idle per Key is set to 1 for situations where the network is broken.
     * Then, on reconnect we can fail all getConnection calls (in the ScraperTask) fast until
     * (in the background) the idle connection is created and the getConnection call returns fast.
     */
    private static PooledPlcDriverManager createPooledDriverManager() {
<span class="nc" id="L103">        return new PooledPlcDriverManager(pooledPlcConnectionFactory -&gt; {</span>
<span class="nc" id="L104">            GenericKeyedObjectPoolConfig&lt;PlcConnection&gt; poolConfig = new GenericKeyedObjectPoolConfig&lt;&gt;();</span>
<span class="nc" id="L105">            poolConfig.setMinIdlePerKey(1);  // This should avoid problems with long running connect attempts??</span>
<span class="nc" id="L106">            poolConfig.setTestOnBorrow(true);</span>
<span class="nc" id="L107">            poolConfig.setTestOnReturn(true);</span>
<span class="nc" id="L108">            return new GenericKeyedObjectPool&lt;&gt;(pooledPlcConnectionFactory, poolConfig);</span>
        });
    }



    @Override
    public void start() {
        // Schedule all jobs
<span class="fc" id="L117">        LOGGER.info(&quot;Starting jobs...&quot;);</span>
<span class="fc" id="L118">        jobs.stream()</span>
<span class="fc" id="L119">            .flatMap(job -&gt; job.getSourceConnections().entrySet().stream()</span>
<span class="fc" id="L120">                .map(entry -&gt; Triple.of(job, entry.getKey(), entry.getValue()))</span>
            )
<span class="fc" id="L122">            .forEach(</span>
                tuple -&gt; {
<span class="fc" id="L124">                    LOGGER.debug(&quot;Register task for job {} for conn {} ({}) at rate {} ms&quot;,</span>
<span class="fc" id="L125">                        tuple.getLeft().getJobName(), tuple.getMiddle(), tuple.getRight(), tuple.getLeft().getScrapeRate());</span>
<span class="fc" id="L126">                    ScraperTask task = new ScraperTaskImpl(driverManager,</span>
<span class="fc" id="L127">                        tuple.getLeft().getJobName(), tuple.getMiddle(), tuple.getRight(),</span>
<span class="fc" id="L128">                        tuple.getLeft().getFields(),</span>
                        1_000,
                        handlerPool, resultHandler);
                    // Add task to internal list
<span class="fc" id="L132">                    tasks.put(tuple.getLeft(), task);</span>
<span class="fc" id="L133">                    ScheduledFuture&lt;?&gt; future = scheduler.scheduleAtFixedRate(task,</span>
<span class="fc" id="L134">                        0, tuple.getLeft().getScrapeRate(), TimeUnit.MILLISECONDS);</span>

                    // Store the handle for stopping, etc.
<span class="fc" id="L137">                    futures.put(task, future);</span>
<span class="fc" id="L138">                }</span>
            );

        // Add statistics tracker
<span class="fc" id="L142">        scheduler.scheduleAtFixedRate(() -&gt; {</span>
<span class="fc bfc" id="L143" title="All 2 branches covered.">            for (Map.Entry&lt;ScrapeJob, ScraperTask&gt; entry : tasks.entries()) {</span>
<span class="fc" id="L144">                DescriptiveStatistics statistics = entry.getValue().getLatencyStatistics();</span>
<span class="fc" id="L145">                String msg = String.format(Locale.ENGLISH, &quot;Job statistics (%s, %s) number of requests: %d (%d success, %.1f %% failed, %.1f %% too slow), min latency: %.2f ms, mean latency: %.2f ms, median: %.2f ms&quot;,</span>
<span class="fc" id="L146">                    entry.getValue().getJobName(), entry.getValue().getConnectionAlias(),</span>
<span class="fc" id="L147">                    entry.getValue().getRequestCounter(), entry.getValue().getSuccessfullRequestCounter(),</span>
<span class="fc" id="L148">                    entry.getValue().getPercentageFailed(),</span>
<span class="fc" id="L149">                    statistics.apply(new PercentageAboveThreshold(entry.getKey().getScrapeRate() * 1e6)),</span>
<span class="fc" id="L150">                    statistics.getMin() * 1e-6, statistics.getMean() * 1e-6, statistics.getPercentile(50) * 1e-6);</span>
<span class="fc" id="L151">                LOGGER.debug(msg);</span>
<span class="fc" id="L152">            }</span>
<span class="fc" id="L153">        }, 1_000, 1_000, TimeUnit.MILLISECONDS);</span>
<span class="fc" id="L154">    }</span>

    /**
     * For testing.
     */
    ScheduledExecutorService getScheduler() {
<span class="fc" id="L160">        return scheduler;</span>
    }

    @Override
    public int getNumberOfActiveTasks() {
<span class="pc bpc" id="L165" title="1 of 2 branches missed.">        return (int) futures.entries().stream().filter(entry -&gt; !entry.getValue().isDone()).count();</span>
    }

    @Override
    public void stop() {
        // Stop all futures
<span class="fc" id="L171">        LOGGER.info(&quot;Stopping scraper...&quot;);</span>
<span class="fc bfc" id="L172" title="All 2 branches covered.">        for (Map.Entry&lt;ScraperTask, ScheduledFuture&lt;?&gt;&gt; entry : futures.entries()) {</span>
<span class="fc" id="L173">            LOGGER.debug(&quot;Stopping task {}...&quot;, entry.getKey());</span>
<span class="fc" id="L174">            entry.getValue().cancel(true);</span>
<span class="fc" id="L175">        }</span>
        // Clear the map
<span class="fc" id="L177">        futures.clear();</span>
<span class="fc" id="L178">    }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>