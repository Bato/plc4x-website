<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>Scraper.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">plc4j-scraper</a> &gt; <a href="index.source.html" class="el_package">org.apache.plc4x.java.scraper</a> &gt; <span class="el_source">Scraper.java</span></div><h1>Scraper.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.plc4x.java.scraper;

import org.apache.commons.collections4.MultiValuedMap;
import org.apache.commons.collections4.multimap.ArrayListValuedHashMap;
import org.apache.commons.lang3.Validate;
import org.apache.commons.lang3.concurrent.BasicThreadFactory;
import org.apache.commons.lang3.tuple.Triple;
import org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;
import org.apache.plc4x.java.PlcDriverManager;
import org.apache.plc4x.java.scraper.config.ScraperConfiguration;
import org.apache.plc4x.java.scraper.util.PercentageAboveThreshold;
import org.apache.plc4x.java.utils.connectionpool.PooledPlcDriverManager;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.concurrent.*;

/**
 * Main class that orchestrates scraping.
 */
public class Scraper {

<span class="fc" id="L45">    private static final Logger LOGGER = LoggerFactory.getLogger(Scraper.class);</span>

<span class="fc" id="L47">    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(10,</span>
        new BasicThreadFactory.Builder()
<span class="fc" id="L49">            .namingPattern(&quot;scheduler-thread-%d&quot;)</span>
<span class="fc" id="L50">            .daemon(false)</span>
<span class="fc" id="L51">            .build()</span>
    );
<span class="fc" id="L53">    private final ExecutorService handlerPool = Executors.newFixedThreadPool(4,</span>
        new BasicThreadFactory.Builder()
<span class="fc" id="L55">            .namingPattern(&quot;handler-thread-%d&quot;)</span>
<span class="fc" id="L56">            .daemon(true)</span>
<span class="fc" id="L57">            .build()</span>
    );

    private final ResultHandler resultHandler;

<span class="fc" id="L62">    private final MultiValuedMap&lt;ScrapeJob, ScraperTask&gt; tasks = new ArrayListValuedHashMap&lt;&gt;();</span>
<span class="fc" id="L63">    private final MultiValuedMap&lt;ScraperTask, ScheduledFuture&lt;?&gt;&gt; futures = new ArrayListValuedHashMap&lt;&gt;();</span>
    private final PlcDriverManager driverManager;
    private final List&lt;ScrapeJob&gt; jobs;

    /**
     * Creates a Scraper instance from a configuration.
     * By default a {@link PooledPlcDriverManager} is used.
     * @param config Configuration to use.
     * @param resultHandler
     */
    public Scraper(ScraperConfiguration config, ResultHandler resultHandler) {
<span class="nc" id="L74">        this(resultHandler, new PooledPlcDriverManager(), config.getJobs());</span>
<span class="nc" id="L75">    }</span>

    /**
     *
     * @param resultHandler
     * @param driverManager
     * @param jobs
     */
<span class="fc" id="L83">    public Scraper(ResultHandler resultHandler, PlcDriverManager driverManager, List&lt;ScrapeJob&gt; jobs) {</span>
<span class="fc" id="L84">        this.resultHandler = resultHandler;</span>
<span class="fc" id="L85">        Validate.notEmpty(jobs);</span>
<span class="fc" id="L86">        this.driverManager = driverManager;</span>
<span class="fc" id="L87">        this.jobs = jobs;</span>
<span class="fc" id="L88">    }</span>

    /**
     * Start the scraping.
     */
    public void start() {
        // Schedule all jobs
<span class="fc" id="L95">        LOGGER.info(&quot;Starting jobs...&quot;);</span>
<span class="fc" id="L96">        jobs.stream()</span>
<span class="fc" id="L97">            .flatMap(job -&gt; job.getConnections().entrySet().stream()</span>
<span class="fc" id="L98">                .map(entry -&gt; Triple.of(job, entry.getKey(), entry.getValue()))</span>
            )
<span class="fc" id="L100">            .forEach(</span>
                tuple -&gt; {
<span class="fc" id="L102">                    LOGGER.debug(&quot;Register task for job {} for conn {} ({}) at rate {} ms&quot;,</span>
<span class="fc" id="L103">                        tuple.getLeft().getName(), tuple.getMiddle(), tuple.getRight(), tuple.getLeft().getScrapeRate());</span>
<span class="fc" id="L104">                    ScraperTask task = new ScraperTask(driverManager,</span>
<span class="fc" id="L105">                        tuple.getLeft().getName(), tuple.getMiddle(), tuple.getRight(),</span>
<span class="fc" id="L106">                        tuple.getLeft().getFields(),</span>
                        1_000,
                        handlerPool, resultHandler);
                    // Add task to internal list
<span class="fc" id="L110">                    tasks.put(tuple.getLeft(), task);</span>
<span class="fc" id="L111">                    ScheduledFuture&lt;?&gt; future = scheduler.scheduleAtFixedRate(task,</span>
<span class="fc" id="L112">                        0, tuple.getLeft().getScrapeRate(), TimeUnit.MILLISECONDS);</span>

                    // Store the handle for stopping, etc.
<span class="fc" id="L115">                    futures.put(task, future);</span>
<span class="fc" id="L116">                }</span>
            );

        // Add statistics tracker
<span class="fc" id="L120">        scheduler.scheduleAtFixedRate(() -&gt; {</span>
<span class="fc bfc" id="L121" title="All 2 branches covered.">            for (Map.Entry&lt;ScrapeJob, ScraperTask&gt; entry : tasks.entries()) {</span>
<span class="fc" id="L122">                DescriptiveStatistics statistics = entry.getValue().getLatencyStatistics();</span>
<span class="fc" id="L123">                String msg = String.format(Locale.ENGLISH, &quot;Job statistics (%s, %s) number of requests: %d (%d success, %.1f %% failed, %.1f %% too slow), min latency: %.2f ms, mean latency: %.2f ms, median: %.2f ms&quot;,</span>
<span class="fc" id="L124">                    entry.getValue().getJobName(), entry.getValue().getConnectionAlias(),</span>
<span class="fc" id="L125">                    entry.getValue().getRequestCounter(), entry.getValue().getSuccessfullRequestCounter(),</span>
<span class="fc" id="L126">                    entry.getValue().getPercentageFailed(),</span>
<span class="fc" id="L127">                    statistics.apply(new PercentageAboveThreshold(entry.getKey().getScrapeRate() * 1e6)),</span>
<span class="fc" id="L128">                    statistics.getMin() * 1e-6, statistics.getMean() * 1e-6, statistics.getPercentile(50) * 1e-6);</span>
<span class="fc" id="L129">                LOGGER.info(msg);</span>
<span class="fc" id="L130">            }</span>
<span class="fc" id="L131">        }, 1_000, 1_000, TimeUnit.MILLISECONDS);</span>
<span class="fc" id="L132">    }</span>

    /**
     * For testing.
     */
    ScheduledExecutorService getScheduler() {
<span class="fc" id="L138">        return scheduler;</span>
    }

    public int getNumberOfActiveTasks() {
<span class="pc bpc" id="L142" title="1 of 2 branches missed.">        return (int) futures.entries().stream().filter(entry -&gt; !entry.getValue().isDone()).count();</span>
    }

    public void stop() {
        // Stop all futures
<span class="fc" id="L147">        LOGGER.info(&quot;Stopping scraper...&quot;);</span>
<span class="fc bfc" id="L148" title="All 2 branches covered.">        for (Map.Entry&lt;ScraperTask, ScheduledFuture&lt;?&gt;&gt; entry : futures.entries()) {</span>
<span class="fc" id="L149">            LOGGER.debug(&quot;Stopping task {}...&quot;, entry.getKey());</span>
<span class="fc" id="L150">            entry.getValue().cancel(true);</span>
<span class="fc" id="L151">        }</span>
        // Clear the map
<span class="fc" id="L153">        futures.clear();</span>
<span class="fc" id="L154">    }</span>

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>