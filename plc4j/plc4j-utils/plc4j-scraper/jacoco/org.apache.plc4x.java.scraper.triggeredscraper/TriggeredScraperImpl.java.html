<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TriggeredScraperImpl.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">PLC4J: Utils: Scraper</a> &gt; <a href="index.source.html" class="el_package">org.apache.plc4x.java.scraper.triggeredscraper</a> &gt; <span class="el_source">TriggeredScraperImpl.java</span></div><h1>TriggeredScraperImpl.java</h1><pre class="source lang-java linenums">/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * &quot;License&quot;); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.plc4x.java.scraper.triggeredscraper;

import org.apache.commons.collections4.MultiValuedMap;
import org.apache.commons.collections4.multimap.ArrayListValuedHashMap;
import org.apache.commons.lang3.Validate;
import org.apache.commons.lang3.concurrent.BasicThreadFactory;
import org.apache.commons.lang3.tuple.Triple;
import org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;
import org.apache.commons.pool2.impl.GenericKeyedObjectPool;
import org.apache.commons.pool2.impl.GenericKeyedObjectPoolConfig;
import org.apache.plc4x.java.PlcDriverManager;
import org.apache.plc4x.java.api.PlcConnection;
import org.apache.plc4x.java.scraper.*;
import org.apache.plc4x.java.scraper.exception.ScraperException;
import org.apache.plc4x.java.scraper.config.triggeredscraper.TriggeredScraperConfiguration;
import org.apache.plc4x.java.scraper.util.PercentageAboveThreshold;
import org.apache.plc4x.java.utils.connectionpool.PooledPlcDriverManager;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.concurrent.*;

/**
 * replaces the old Scraper that only could do scheduled scraping jobs
 * Triggers have been introduced, so that in configuration &quot;scrapeTime&quot; has been exchanged by &quot;triggerConfig&quot;
 *
 * Some example:
 *   - 200ms scheduling is now performed by &quot;triggerConfig: (SCHEDULED,200)&quot; in scraper-configuration
 *   - a triggered S7 variable can be used as follows:
 *     &quot;triggerConfig: (S7_TRIGGER_VAR,10,(%M0.3:BOOL)==(true))&quot; meaning that Boolean in Marker-Block in Byte-Offset 0, Bit-Offset 3 is scanned every 10ms, when trigger has a rising-edge the acquirement of data-block is triggered
 *     the trigger variable must be a valid address as defined with PLC4X-S7-Driver
 *     right now boolean variables as well as numeric variables could be used as data-types
 *     available comparators are ==,!= for all data-types and &amp;gt;,&amp;gt;=,&amp;lt;,&amp;lt;= for numeric data-types
 */
public class TriggeredScraperImpl implements Scraper {

<span class="nc" id="L59">    private static final Logger LOGGER = LoggerFactory.getLogger(TriggeredScraperImpl.class);</span>

<span class="nc" id="L61">    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(10,</span>
        new BasicThreadFactory.Builder()
<span class="nc" id="L63">            .namingPattern(&quot;triggeredscraper-scheduling-thread-%d&quot;)</span>
<span class="nc" id="L64">            .daemon(false)</span>
<span class="nc" id="L65">            .build()</span>
    );
<span class="nc" id="L67">    private final ExecutorService executorService = Executors.newFixedThreadPool(4,</span>
        new BasicThreadFactory.Builder()
<span class="nc" id="L69">            .namingPattern(&quot;triggeredscraper-executer-thread-%d&quot;)</span>
<span class="nc" id="L70">            .daemon(true)</span>
<span class="nc" id="L71">            .build()</span>
    );

    private final ResultHandler resultHandler;

<span class="nc" id="L76">    private final MultiValuedMap&lt;ScrapeJob, ScraperTask&gt; tasks = new ArrayListValuedHashMap&lt;&gt;();</span>
<span class="nc" id="L77">    private final MultiValuedMap&lt;ScraperTask, ScheduledFuture&lt;?&gt;&gt; futures = new ArrayListValuedHashMap&lt;&gt;();</span>
    private final PlcDriverManager driverManager;
    private final List&lt;ScrapeJob&gt; jobs;

    /**
     * Creates a Scraper instance from a configuration.
     * By default a {@link PooledPlcDriverManager} is used.
     * @param config Configuration to use.
     * @param resultHandler
     */
    public TriggeredScraperImpl(TriggeredScraperConfiguration config, ResultHandler resultHandler) throws ScraperException {
<span class="nc" id="L88">        this(resultHandler, createPooledDriverManager(), config.getJobs());</span>
<span class="nc" id="L89">    }</span>

    /**
     * Min Idle per Key is set to 1 for situations where the network is broken.
     * Then, on reconnect we can fail all getConnection calls (in the ScraperTask) fast until
     * (in the background) the idle connection is created and the getConnection call returns fast.
     */
    private static PooledPlcDriverManager createPooledDriverManager() {
<span class="nc" id="L97">        return new PooledPlcDriverManager(pooledPlcConnectionFactory -&gt; {</span>
<span class="nc" id="L98">            GenericKeyedObjectPoolConfig&lt;PlcConnection&gt; poolConfig = new GenericKeyedObjectPoolConfig&lt;&gt;();</span>
<span class="nc" id="L99">            poolConfig.setMinIdlePerKey(1);  // This should avoid problems with long running connect attempts??</span>
<span class="nc" id="L100">            poolConfig.setTestOnBorrow(true);</span>
<span class="nc" id="L101">            poolConfig.setTestOnReturn(true);</span>
<span class="nc" id="L102">            return new GenericKeyedObjectPool&lt;&gt;(pooledPlcConnectionFactory, poolConfig);</span>
        });
    }


<span class="nc" id="L107">    public TriggeredScraperImpl(ResultHandler resultHandler, PlcDriverManager driverManager, List&lt;ScrapeJob&gt; jobs) {</span>
<span class="nc" id="L108">        this.resultHandler = resultHandler;</span>
<span class="nc" id="L109">        Validate.notEmpty(jobs);</span>
<span class="nc" id="L110">        this.driverManager = driverManager;</span>
<span class="nc" id="L111">        this.jobs = jobs;</span>
<span class="nc" id="L112">    }</span>

    /**
     * Start the scraping.
     */
    //ToDo code-refactoring and improved testing --&gt; PLC4X-90
    @Override
    public void start() {
        // Schedule all jobs
<span class="nc" id="L121">        LOGGER.info(&quot;Starting jobs...&quot;);</span>
<span class="nc" id="L122">        jobs.stream()</span>
<span class="nc" id="L123">            .flatMap(job -&gt; job.getSourceConnections().entrySet().stream()</span>
<span class="nc" id="L124">                .map(entry -&gt; Triple.of(job, entry.getKey(), entry.getValue()))</span>
            )
<span class="nc" id="L126">            .forEach(</span>
                tuple -&gt; {
<span class="nc" id="L128">                    LOGGER.debug(&quot;Register task for job {} for conn {} ({}) at rate {} ms&quot;,</span>
<span class="nc" id="L129">                        tuple.getLeft().getJobName(), tuple.getMiddle(), tuple.getRight(), tuple.getLeft().getScrapeRate());</span>
<span class="nc" id="L130">                    TriggeredScraperTask task =</span>
                        null;
                    try {
<span class="nc" id="L133">                        task = new TriggeredScraperTask(driverManager,</span>
<span class="nc" id="L134">                            tuple.getLeft().getJobName(),</span>
<span class="nc" id="L135">                            tuple.getMiddle(),</span>
<span class="nc" id="L136">                            tuple.getRight(),</span>
<span class="nc" id="L137">                            tuple.getLeft().getFields(),</span>
                            1_000,
                            executorService,
                            resultHandler,
<span class="nc" id="L141">                            (TriggeredScrapeJobImpl) tuple.getLeft());</span>
                        // Add task to internal list
<span class="nc" id="L143">                        tasks.put(tuple.getLeft(), task);</span>
<span class="nc" id="L144">                        ScheduledFuture&lt;?&gt; future = scheduler.scheduleAtFixedRate(task,</span>
<span class="nc" id="L145">                            0, tuple.getLeft().getScrapeRate(), TimeUnit.MILLISECONDS);</span>

                        // Store the handle for stopping, etc.
<span class="nc" id="L148">                        futures.put(task, future);</span>
<span class="nc" id="L149">                    } catch (ScraperException e) {</span>
<span class="nc" id="L150">                        LOGGER.warn(&quot;Error executing the job {} for conn {} ({}) at rate {} ms&quot;,tuple.getLeft().getJobName(), tuple.getMiddle(), tuple.getRight(), tuple.getLeft().getScrapeRate(),e);</span>
<span class="nc" id="L151">                    }</span>

<span class="nc" id="L153">                }</span>
            );

        // Add statistics tracker
<span class="nc" id="L157">        scheduler.scheduleAtFixedRate(() -&gt; {</span>
<span class="nc bnc" id="L158" title="All 2 branches missed.">            for (Map.Entry&lt;ScrapeJob, ScraperTask&gt; entry : tasks.entries()) {</span>
<span class="nc" id="L159">                DescriptiveStatistics statistics = entry.getValue().getLatencyStatistics();</span>
<span class="nc" id="L160">                String msg = String.format(Locale.ENGLISH, &quot;Job statistics (%s, %s) number of requests: %d (%d success, %.1f %% failed, %.1f %% too slow), min latency: %.2f ms, mean latency: %.2f ms, median: %.2f ms&quot;,</span>
<span class="nc" id="L161">                    entry.getValue().getJobName(), entry.getValue().getConnectionAlias(),</span>
<span class="nc" id="L162">                    entry.getValue().getRequestCounter(), entry.getValue().getSuccessfullRequestCounter(),</span>
<span class="nc" id="L163">                    entry.getValue().getPercentageFailed(),</span>
<span class="nc" id="L164">                    statistics.apply(new PercentageAboveThreshold(entry.getKey().getScrapeRate() * 1e6)),</span>
<span class="nc" id="L165">                    statistics.getMin() * 1e-6, statistics.getMean() * 1e-6, statistics.getPercentile(50) * 1e-6);</span>
<span class="nc" id="L166">                LOGGER.debug(msg);</span>
<span class="nc" id="L167">            }</span>
<span class="nc" id="L168">        }, 1_000, 1_000, TimeUnit.MILLISECONDS);</span>
<span class="nc" id="L169">    }</span>

    @Override
    public int getNumberOfActiveTasks() {
<span class="nc" id="L173">        return 0;</span>
    }

    @Override
    public void stop() {
        // Stop all futures
<span class="nc" id="L179">        LOGGER.info(&quot;Stopping scraper...&quot;);</span>
<span class="nc bnc" id="L180" title="All 2 branches missed.">        for (Map.Entry&lt;ScraperTask, ScheduledFuture&lt;?&gt;&gt; entry : futures.entries()) {</span>
<span class="nc" id="L181">            LOGGER.debug(&quot;Stopping task {}...&quot;, entry.getKey());</span>
<span class="nc" id="L182">            entry.getValue().cancel(true);</span>
<span class="nc" id="L183">        }</span>
        // Clear the map
<span class="nc" id="L185">        futures.clear();</span>
<span class="nc" id="L186">    }</span>
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.2.201808211720</span></div></body></html>